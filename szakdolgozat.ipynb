{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import swifter\n",
    "import math\n",
    "from statsbombpy import sb\n",
    "#from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "#from sympy import symbols, Eq, solve\n",
    "#import sympy as sp\n",
    "#from scipy.integrate import quad\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, StackingRegressor\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n",
    "from sklearn import tree, svm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare and download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = os.listdir('three-sixty')\n",
    "tracking_df = pd.DataFrame()\n",
    "for i in json_list:\n",
    "    # skip the json files which does not have the right format\n",
    "    try:\n",
    "        match_df = pd.read_json(f'three-sixty/{i}')\n",
    "        tracking_df = pd.concat([tracking_df,match_df])\n",
    "    except:\n",
    "        print(i)\n",
    "event_df = pd.DataFrame()\n",
    "for i in json_list:\n",
    "    tmp_event_df = sb.events(match_id = i[:-5])\n",
    "    event_df = pd.concat([event_df,tmp_event_df])\n",
    "tracking_df = tracking_df.explode(\"freeze_frame\", ignore_index=True)\n",
    "freeze_frame = pd.json_normalize(tracking_df[\"freeze_frame\"]).add_prefix(\"freezeFrame_\")\n",
    "tracking_df = pd.concat([tracking_df, freeze_frame], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_df['freezeFrame_x'] = tracking_df['freezeFrame_location'].swifter.apply(lambda x: x[0])\n",
    "tracking_df['freezeFrame_y'] = tracking_df['freezeFrame_location'].apply(lambda x: x[1])\n",
    "event_df['location_x'] = event_df['location'].swifter.apply(lambda x: x[0] if type(x) == list else np.nan)\n",
    "event_df['location_y'] = event_df['location'].swifter.apply(lambda x: x[1] if type(x) == list else np.nan)\n",
    "\n",
    "\n",
    "\n",
    "event_df['end_location'] = event_df['shot_end_location']\n",
    "event_df['end_location'] = np.where(pd.isna(event_df['end_location'])!=False,\n",
    "                            event_df['pass_end_location'], np.where(pd.isna(event_df['end_location'])!=False,\n",
    "                            event_df['carry_end_location'], np.where(pd.isna(event_df['end_location'])!=False,\n",
    "                            event_df['goalkeeper_end_location'], event_df['end_location'])))\n",
    "event_df['end_location_x'] = event_df['end_location'].swifter.apply(lambda x: x[0] if type(x) == list else np.nan)\n",
    "event_df['end_location_y'] = event_df['end_location'].swifter.apply(lambda x: x[1] if type(x) == list else np.nan)\n",
    "event_df['end_location_z'] = event_df['end_location'].swifter.apply(lambda x: x[2] if type(x) == list and len(x)==3 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = event_df.sort_values(by=['match_id', 'period', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df['goal_success'] = 0\n",
    "for i in range(20):\n",
    "    event_df['goal_success'] = np.where(((event_df['shot_outcome'].shift(-i) == 'Goal')&(event_df['play_pattern'].shift(-i) == event_df['play_pattern'])&(((pd.to_datetime(event_df['timestamp'])-pd.to_datetime(event_df['timestamp']).shift(-i)).dt.total_seconds())<=20)), 1, event_df['goal_success'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df['pass_height_number'] = np.where(event_df['pass_height'] == 'High Pass', 2.2,\n",
    "                        np.where(event_df['pass_height'] == 'Low Pass', 1.2,\n",
    "                        np.where(event_df['pass_height'] == 'Ground Pass', 0.1, np.nan)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df['pass_height_number'] = np.where(((event_df['pass_height_number'].isna())&(~event_df['end_location_z'].isna())),\n",
    "                                          event_df['end_location_z'], event_df['pass_height_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df['pass_height_number'] = event_df['pass_height_number'].fillna(event_df[event_df['shot_type']=='Free Kick']['pass_height_number'].mean())\n",
    "event_df['pass_height_number'] = event_df['pass_height_number'].fillna(event_df[event_df['shot_type']=='Throw-in']['pass_height_number'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df['pass_length'] = np.where(((event_df['pass_length'].isna())),\n",
    "                        (np.sqrt(((event_df['end_location_x']-event_df['location_x'])**2)+((event_df['end_location_y']-event_df['location_y'])**2))),\n",
    "                        event_df['pass_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_dict={15:[0,16.5,0,20],12:[16.5,45.5,0,20],9:[45.5,74.5,0,20],6:[74.5,103.5,0,20],3:[103.5,121,0,20],\n",
    "           14:[0,16.5,20,31],11:[16.5,45.5,20,31],8:[45.5,74.5,20,31],5:[74.5,103.5,20,31],2:[103.5,121,20,31],\n",
    "           13:[0,16.5,31,49],10:[16.5,45.5,31,49],7:[45.5,74.5,31,49],4:[74.5,103.5,31,49],1:[103.5,121,31,49],\n",
    "           -14:[0,16.5,49,60],-11:[16.5,45.5,49,60],-8:[45.5,74.5,49,60],-5:[74.5,103.5,49,60],-2:[103.5,121,49,60],\n",
    "           -15:[0,16.5,60,81],-12:[16.5,45.5,60,81],-9:[45.5,74.5,60,81],-6:[74.5,103.5,60,81],-3:[103.5,121,60,81]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df['zone'] = 0\n",
    "event_df['end_zone'] = 0\n",
    "for key,value in zone_dict.items():\n",
    "  event_df['zone'] = np.where(((event_df['location_x']>value[0])&(event_df['location_x']<=value[1])&(event_df['location_y']>value[2])&(event_df['location_y']<=value[3])),key,event_df['zone'])\n",
    "  event_df['end_zone'] = np.where(((event_df['end_location_x']>value[0])&(event_df['end_location_x']<=value[1])&(event_df['end_location_y']>value[2])&(event_df['end_location_y']<=value[3])),key,event_df['end_zone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df['zone'] = event_df['zone'].abs()\n",
    "event_df['end_zone'] = event_df['end_zone'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_df['tmp_cnt']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = event_df[(event_df['pass_type']=='Corner')|\\\n",
    "    (event_df['shot_type']=='Corner')|\\\n",
    "    ((event_df['shot_type']=='Free Kick')&(event_df['location_x']>=80))|\\\n",
    "    ((event_df['pass_type']=='Free Kick')&(event_df['location_x']>=80))|\\\n",
    "    ((event_df['pass_type']=='Throw-in')&(event_df['location_x']>=80))|\\\n",
    "    ((event_df['shot_type']=='Throw-in')&(event_df['location_x']>=80))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id_list = list(event_df['id'].unique())\n",
    "# working with only the needed rows to use less memory -> the code will be faster\n",
    "tracking_df = tracking_df[tracking_df['event_uuid'].isin(event_id_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density(row):\n",
    "    all_dens = tracking_df[tracking_df['event_uuid']==row['id']]\n",
    "    \n",
    "    all_dens['tmp'] = ((all_dens['freezeFrame_x'] - row['end_location_x'])**2 + (all_dens['freezeFrame_y'] - row['end_location_y'])**2)**0.5\n",
    "    \n",
    "    all_dens = all_dens[all_dens['tmp']<=5]\n",
    "    \n",
    "    return all_dens.tmp_cnt.astype(\"Int64\").sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_id_list = list(tracking_df['event_uuid'].unique())\n",
    "event_df = event_df[event_df['id'].isin(tracking_id_list)]\n",
    "event_df['density'] = event_df.swifter.apply(density, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the parabolic arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df['arc'] = (4*event_df['pass_height_number']+np.sqrt(event_df['pass_length']**2 +16*event_df['pass_height_number']**2))/event_df['pass_length']\n",
    "event_df['arc'] = np.log10(event_df['arc'])\n",
    "event_df['arc'] = ((event_df['pass_length']**2)*event_df['arc'])/(8*(event_df['pass_height_number']**2))\n",
    "event_df['arc'] = (0.5*np.sqrt(event_df['pass_length']**2 +16*event_df['pass_height_number']**2)) + event_df['arc']\n",
    "event_df['arc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df['color'] = np.where(event_df['shot_outcome'] == 'Goal', 'red', np.where(event_df['goal_success']==1, 'orange', 'black'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_kicks_df = event_df[((event_df['shot_type']=='Free Kick')|(event_df['pass_type']=='Free Kick'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_colors = list(event_df.color.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "handle_lits=[]\n",
    "legend_list=[]\n",
    "scatter_handles = []\n",
    "for current_color in all_colors:\n",
    "    print(current_color)\n",
    "    current_df = free_kicks_df[free_kicks_df['color']==current_color]\n",
    "    ax.scatter(current_df['location_x'], current_df['location_y'], c=current_color, \n",
    "                marker=\"o\",\n",
    "                sizes=current_df['shot_statsbomb_xg']*1000,\n",
    "                )\n",
    "\n",
    "img = plt.imread(\"half_pitch.png\")\n",
    "ax.imshow(img, extent=[60, 120, 0, 80])\n",
    "ax.set_xlim(60, 120)\n",
    "ax.set_ylim(0, 80)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners_df = event_df[((event_df['pass_type']=='Corner')|(event_df['shot_type']=='Corner'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i, row in corners_df.iterrows():\n",
    "    ax.annotate(\"\", xy=(row['end_location_x'], row['end_location_y']), xytext=(row['location_x'], row['location_y']),\n",
    "                arrowprops=dict(arrowstyle=\"->\", color = row['color']))\n",
    "    \n",
    "img = plt.imread(\"half_pitch.png\")\n",
    "ax.imshow(img, extent=[60, 120, 0, 80])\n",
    "\n",
    "ax.set_xlim(60, 120)\n",
    "ax.set_ylim(0, 80)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners_right = corners_df[corners_df['location_y']<40]\n",
    "corners_left = corners_df[corners_df['location_y']>=40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for current_color in all_colors:\n",
    "    current_df = corners_left[corners_left['color']==current_color]\n",
    "    plt.scatter(current_df['end_location_x'], current_df['end_location_y'], c=current_color, \n",
    "                linewidths=2, \n",
    "                marker=\"o\",\n",
    "                )\n",
    "img = plt.imread(\"half_pitch.png\")\n",
    "ax.imshow(img, extent=[60, 120, 0, 80])\n",
    "ax.set_xlim(60, 120)\n",
    "ax.set_ylim(0, 80)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for current_color in all_colors:\n",
    "    current_df = corners_right[corners_right['color']==current_color]\n",
    "    plt.scatter(current_df['end_location_x'], current_df['end_location_y'], c=current_color, \n",
    "                linewidths=2, \n",
    "                marker=\"o\",\n",
    "                )\n",
    "img = plt.imread(\"half_pitch.png\")\n",
    "ax.imshow(img, extent=[60, 120, 0, 80])\n",
    "ax.set_xlim(60, 120)\n",
    "ax.set_ylim(0, 80)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throw_in_df = event_df[((event_df['pass_type']=='Throw-in')|(event_df['shot_type']=='Throw-in'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for current_color in all_colors:\n",
    "    current_df = throw_in_df[throw_in_df['color']==current_color]\n",
    "    for i, row in current_df.iterrows():\n",
    "        ax.annotate(\"\", xy=(row['end_location_x'], row['end_location_y']), xytext=(row['location_x'], row['location_y']),\n",
    "                    arrowprops=dict(arrowstyle=\"->\", color = current_color))\n",
    "    \n",
    "img = plt.imread(\"full_pitch.png\")\n",
    "ax.imshow(img, extent=[0, 120, 0, 80])\n",
    "\n",
    "ax.set_xlim(0, 120)\n",
    "ax.set_ylim(0, 80)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throw_in_right = throw_in_df[throw_in_df['location_y']<40]\n",
    "throw_in_left = throw_in_df[throw_in_df['location_y']>=40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for current_color in all_colors:\n",
    "    current_df = throw_in_left[throw_in_left['color']==current_color]\n",
    "    plt.scatter(current_df['end_location_x'], current_df['end_location_y'], c=current_color, \n",
    "                linewidths=2, \n",
    "                marker=\"o\",\n",
    "                )\n",
    "img = plt.imread(\"full_pitch.png\")\n",
    "ax.imshow(img, extent=[0, 120, 0, 80])\n",
    "ax.set_xlim(0, 120)\n",
    "ax.set_ylim(0, 80)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for current_color in all_colors:\n",
    "    current_df = throw_in_right[throw_in_right['color']==current_color]\n",
    "    plt.scatter(current_df['end_location_x'], current_df['end_location_y'], c=current_color, \n",
    "                linewidths=2, \n",
    "                marker=\"o\",\n",
    "                )\n",
    "img = plt.imread(\"full_pitch.png\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels)\n",
    "ax.imshow(img, extent=[0, 120, 0, 80])\n",
    "ax.set_xlim(0, 120)\n",
    "ax.set_ylim(0, 80)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throw ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan = throw_in_df[['goal_success', 'pass_height_number', 'pass_length',\n",
    "      'zone', 'end_zone', 'density', 'arc']].dropna()\n",
    "df_nan['pass_height_number'] = df_nan['pass_height_number'].astype('int64')\n",
    "Train=df_nan\n",
    "Xr_p=Train.drop(columns=['goal_success'])\n",
    "yr_p=Train['goal_success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42, k_neighbors=3)\n",
    "X_res, y_res = sm.fit_resample(Xr_p, yr_p)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train_scaled, y_train)\n",
    "y_pred_p=clf.predict(X_test_scaled)\n",
    "clf.predict_proba(X_test_scaled)\n",
    "score=clf.score(X_train_scaled, y_train)\n",
    "rmse=np.sqrt(metrics.mean_squared_error(y_test,y_pred_p))\n",
    "r2_score=metrics.r2_score(y_test,y_pred_p)\n",
    "log_loss=metrics.log_loss(y_test,y_pred_p)\n",
    "f1 = f1_score(y_test, y_pred_p)\n",
    "roc_a = roc_auc_score(y_test, y_pred_p)\n",
    "print('score: ',score)\n",
    "print('rmse: ',rmse)\n",
    "print('r2_score: ',r2_score)\n",
    "print('log_loss ',log_loss)\n",
    "print('f1 score: ', f1)\n",
    "print('roc auc score', roc_a)\n",
    "\n",
    "importance=clf.coef_[0]\n",
    "\n",
    "for val in enumerate(importance):\n",
    "    print(\"importance score  : {} \".format(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossV_accuracy = cross_val_score(clf, X_res, y_res, cv=5, scoring='accuracy')\n",
    "crossV_f1 = cross_val_score(clf, X_res, y_res, cv=5, scoring='f1')\n",
    "crossV_predict = cross_val_predict(clf, X_res, y_res, cv=5, method='predict')\n",
    "print('accuracy: ', crossV_accuracy)\n",
    "print('f1 score: ', crossV_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predictions = rf_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('accuracy: ',accuracy)\n",
    "print('f1 score: ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossV_accuracy = cross_val_score(rf_model, X_res, y_res, cv=5, scoring='accuracy')\n",
    "crossV_f1 = cross_val_score(rf_model, X_res, y_res, cv=5, scoring='f1')\n",
    "crossV_predict = cross_val_predict(rf_model, X_res, y_res, cv=5, method='predict')\n",
    "print('accuracy: ', crossV_accuracy)\n",
    "print('f1 score: ', crossV_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_model = XGBClassifier()\n",
    "xgbc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgbc_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('accuracy: ',accuracy)\n",
    "print('f1 score: ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossV_accuracy = cross_val_score(xgbc_model, X_res, y_res, cv=5, scoring='accuracy')\n",
    "crossV_f1 = cross_val_score(xgbc_model, X_res, y_res, cv=5, scoring='f1')\n",
    "crossV_predict = cross_val_predict(xgbc_model, X_res, y_res, cv=5, method='predict')\n",
    "print('accuracy: ', crossV_accuracy)\n",
    "print('f1 score: ', crossV_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = tree.DecisionTreeClassifier()\n",
    "dtc = dtc.fit(X_train, y_train)\n",
    "\n",
    "predictions = dtc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('accuracy: ',accuracy)\n",
    "print('f1 score: ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossV_accuracy = cross_val_score(dtc, X_res, y_res, cv=5, scoring='accuracy')\n",
    "crossV_f1 = cross_val_score(dtc, X_res, y_res, cv=5, scoring='f1')\n",
    "crossV_predict = cross_val_predict(dtc, X_res, y_res, cv=5, method='predict')\n",
    "print('accuracy: ', crossV_accuracy)\n",
    "print('f1 score: ', crossV_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC(kernel='linear')\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "predictions = svm_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('accuracy: ',accuracy)\n",
    "print('f1 score: ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossV_accuracy = cross_val_score(svm_model, X_res, y_res, cv=5, scoring='accuracy')\n",
    "crossV_f1 = cross_val_score(svm_model, X_res, y_res, cv=5, scoring='f1')\n",
    "crossV_predict = cross_val_predict(svm_model, X_res, y_res, cv=5, method='predict')\n",
    "print('accuracy: ', crossV_accuracy)\n",
    "print('f1 score: ', crossV_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stck_model = StackingClassifier(\n",
    "    estimators=[('rf', rf_model), ('xgb', xgbc_model), ('log reg', clf), ('decision tree', dtc), ('svm', svm_model)],\n",
    "    final_estimator=xgbc_model\n",
    ")\n",
    "stck_model.fit(X_train, y_train)\n",
    "stck_predictions = stck_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, stck_predictions)\n",
    "r2_score = stck_model.score(X_test, stck_predictions)\n",
    "f1 = f1_score(y_test, stck_predictions)\n",
    "print('accuracy: ',accuracy)\n",
    "print('f1 score: ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, stck_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossV_accuracy = cross_val_score(stck_model, X_res, y_res, cv=5, scoring='accuracy')\n",
    "crossV_f1 = cross_val_score(stck_model, X_res, y_res, cv=5, scoring='f1')\n",
    "crossV_predict = cross_val_predict(stck_model, X_res, y_res, cv=5, method='predict')\n",
    "print('accuracy: ', crossV_accuracy)\n",
    "print('f1 score: ', crossV_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_importance=clf.coef_[0]\n",
    "rf_importance = rf_model.feature_importances_\n",
    "xgbc_importance = xgbc_model.feature_importances_\n",
    "dtc_importance = dtc.feature_importances_\n",
    "svm_importance = svm_model.coef_[0]\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'log_reg': log_reg_importance,\n",
    "                                      'random_forest': rf_importance, 'XGBClassifier': xgbc_importance,\n",
    "                                      'decision_tree': dtc_importance, 'svm': svm_importance\n",
    "                                      })\n",
    "feature_importance_df['log_reg'] = (feature_importance_df['log_reg'].abs())/(feature_importance_df['log_reg'].abs().sum())\n",
    "feature_importance_df['svm'] = (feature_importance_df['svm'].abs())/(feature_importance_df['svm'].abs().sum())\n",
    "feature_importance_df['feature_avg'] = np.mean([feature_importance_df['log_reg'].values, rf_importance, xgbc_importance,\n",
    "                                                dtc_importance, feature_importance_df['svm'].values], axis=0)\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free kicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan = free_kicks_df[['goal_success', 'pass_height_number', 'pass_length',\n",
    "      'zone', 'end_zone', 'density', 'arc', 'shot_statsbomb_xg']].dropna()\n",
    "df_nan['pass_height_number'] = df_nan['pass_height_number'].astype('int64')\n",
    "Train=df_nan\n",
    "Xr_p=Train.drop(columns=['goal_success'])\n",
    "yr_p=Train['goal_success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42, k_neighbors=3)\n",
    "X_res, y_res = sm.fit_resample(Xr_p, yr_p)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train_scaled, y_train)\n",
    "y_pred_p=clf.predict(X_test_scaled)\n",
    "clf.predict_proba(X_test_scaled)\n",
    "score=clf.score(X_train_scaled, y_train)\n",
    "rmse=np.sqrt(metrics.mean_squared_error(y_test,y_pred_p))\n",
    "r2_score=metrics.r2_score(y_test,y_pred_p)\n",
    "log_loss=metrics.log_loss(y_test,y_pred_p)\n",
    "f1 = f1_score(y_test, y_pred_p)\n",
    "roc_a = roc_auc_score(y_test, y_pred_p)\n",
    "print('score: ',score)\n",
    "print('rmse: ',rmse)\n",
    "print('r2_score: ',r2_score)\n",
    "print('log_loss ',log_loss)\n",
    "print('f1 score: ', f1)\n",
    "print('roc auc score', roc_a)\n",
    "\n",
    "importance=clf.coef_[0]\n",
    "\n",
    "for val in enumerate(importance):\n",
    "    print(\"importance score  : {} \".format(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossV_accuracy = cross_val_score(clf, X_res, y_res, cv=5, scoring='accuracy')\n",
    "crossV_f1 = cross_val_score(clf, X_res, y_res, cv=5, scoring='f1')\n",
    "crossV_predict = cross_val_predict(clf, X_res, y_res, cv=5, method='predict')\n",
    "print('accuracy: ', crossV_accuracy)\n",
    "print('f1 score: ', crossV_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "\n",
    "predictions = rf_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('accuracy: ',accuracy)\n",
    "print('f1 score: ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossV_accuracy = cross_val_score(rf_model, X_res, y_res, cv=5, scoring='accuracy')\n",
    "crossV_f1 = cross_val_score(rf_model, X_res, y_res, cv=5, scoring='f1')\n",
    "crossV_predict = cross_val_predict(rf_model, X_res, y_res, cv=5, method='predict')\n",
    "print('accuracy: ', crossV_accuracy)\n",
    "print('f1 score: ', crossV_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_model = XGBClassifier()\n",
    "xgbc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgbc_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('accuracy: ',accuracy)\n",
    "print('f1 score: ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossV_accuracy = cross_val_score(xgbc_model, X_res, y_res, cv=5, scoring='accuracy')\n",
    "crossV_f1 = cross_val_score(xgbc_model, X_res, y_res, cv=5, scoring='f1')\n",
    "crossV_predict = cross_val_predict(xgbc_model, X_res, y_res, cv=5, method='predict')\n",
    "print('accuracy: ', crossV_accuracy)\n",
    "print('f1 score: ', crossV_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = tree.DecisionTreeClassifier()\n",
    "dtc = dtc.fit(X_train, y_train)\n",
    "\n",
    "predictions = dtc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('accuracy: ',accuracy)\n",
    "print('f1 score: ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossV_accuracy = cross_val_score(xgbc_model, X_res, y_res, cv=5, scoring='accuracy')\n",
    "crossV_f1 = cross_val_score(xgbc_model, X_res, y_res, cv=5, scoring='f1')\n",
    "crossV_predict = cross_val_predict(xgbc_model, X_res, y_res, cv=5, method='predict')\n",
    "print('accuracy: ', crossV_accuracy)\n",
    "print('f1 score: ', crossV_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC(kernel='linear')\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "predictions = svm_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('accuracy: ',accuracy)\n",
    "print('f1 score: ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossV_accuracy = cross_val_score(dtc, X_res, y_res, cv=5, scoring='accuracy')\n",
    "crossV_f1 = cross_val_score(dtc, X_res, y_res, cv=5, scoring='f1')\n",
    "crossV_predict = cross_val_predict(dtc, X_res, y_res, cv=5, method='predict')\n",
    "print('accuracy: ', crossV_accuracy)\n",
    "print('f1 score: ', crossV_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stck_model = StackingClassifier(\n",
    "    estimators=[('rf', rf_model), ('xgb', xgbc_model), ('log reg', clf), ('decision tree', dtc), ('svm', svm_model)],\n",
    "    final_estimator=xgbc_model\n",
    ")\n",
    "stck_model.fit(X_train, y_train)\n",
    "stck_predictions = stck_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, stck_predictions)\n",
    "r2_score = stck_model.score(X_test, stck_predictions)\n",
    "f1 = f1_score(y_test, stck_predictions)\n",
    "print('accuracy: ',accuracy)\n",
    "print('f1 score: ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, stck_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossV_accuracy = cross_val_score(stck_model, X_res, y_res, cv=5, scoring='accuracy')\n",
    "crossV_f1 = cross_val_score(stck_model, X_res, y_res, cv=5, scoring='f1')\n",
    "crossV_predict = cross_val_predict(stck_model, X_res, y_res, cv=5, method='predict')\n",
    "print('accuracy: ', crossV_accuracy)\n",
    "print('f1 score: ', crossV_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_importance=clf.coef_[0]\n",
    "rf_importance = rf_model.feature_importances_\n",
    "xgbc_importance = xgbc_model.feature_importances_\n",
    "dtc_importance = dtc.feature_importances_\n",
    "svm_importance = svm_model.coef_[0]\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'log_reg': log_reg_importance,\n",
    "                                      'random_forest': rf_importance, 'XGBClassifier': xgbc_importance,\n",
    "                                      'decision_tree': dtc_importance, 'svm': svm_importance\n",
    "                                      })\n",
    "feature_importance_df['log_reg'] = (feature_importance_df['log_reg'].abs())/(feature_importance_df['log_reg'].abs().sum())\n",
    "feature_importance_df['svm'] = (feature_importance_df['svm'].abs())/(feature_importance_df['svm'].abs().sum())\n",
    "feature_importance_df['feature_avg'] = np.mean([feature_importance_df['log_reg'].values, rf_importance, xgbc_importance,\n",
    "                                                dtc_importance, feature_importance_df['svm'].values], axis=0)\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan = corners_df[['goal_success', 'pass_height_number', 'pass_length',\n",
    "      'zone', 'end_zone', 'density', 'arc']].dropna()\n",
    "df_nan['pass_height_number'] = df_nan['pass_height_number'].astype('int64')\n",
    "Train=df_nan\n",
    "Xr_p=Train.drop(columns=['goal_success'])\n",
    "yr_p=Train['goal_success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42, k_neighbors=3)\n",
    "X_res, y_res = sm.fit_resample(Xr_p, yr_p)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train_scaled, y_train)\n",
    "y_pred_p=clf.predict(X_test_scaled)\n",
    "clf.predict_proba(X_test_scaled)\n",
    "score=clf.score(X_train_scaled, y_train)\n",
    "rmse=np.sqrt(metrics.mean_squared_error(y_test,y_pred_p))\n",
    "r2_score=metrics.r2_score(y_test,y_pred_p)\n",
    "log_loss=metrics.log_loss(y_test,y_pred_p)\n",
    "f1 = f1_score(y_test, y_pred_p)\n",
    "roc_a = roc_auc_score(y_test, y_pred_p)\n",
    "print('score: ',score)\n",
    "print('rmse: ',rmse)\n",
    "print('r2_score: ',r2_score)\n",
    "print('log_loss ',log_loss)\n",
    "print('f1 score: ', f1)\n",
    "print('roc auc score', roc_a)\n",
    "\n",
    "importance=clf.coef_[0]\n",
    "\n",
    "for val in enumerate(importance):\n",
    "    print(\"importance score  : {} \".format(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossV_accuracy = cross_val_score(clf, X_res, y_res, cv=5, scoring='accuracy')\n",
    "crossV_f1 = cross_val_score(clf, X_res, y_res, cv=5, scoring='f1')\n",
    "crossV_predict = cross_val_predict(clf, X_res, y_res, cv=5, method='predict')\n",
    "print('accuracy: ', crossV_accuracy)\n",
    "print('f1 score: ', crossV_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "\n",
    "predictions = rf_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('accuracy: ',accuracy)\n",
    "print('f1 score: ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossV_accuracy = cross_val_score(rf_model, X_res, y_res, cv=5, scoring='accuracy')\n",
    "crossV_f1 = cross_val_score(rf_model, X_res, y_res, cv=5, scoring='f1')\n",
    "crossV_predict = cross_val_predict(rf_model, X_res, y_res, cv=5, method='predict')\n",
    "print('accuracy: ', crossV_accuracy)\n",
    "print('f1 score: ', crossV_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_model = XGBClassifier()\n",
    "xgbc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgbc_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('accuracy: ',accuracy)\n",
    "print('f1 score: ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossV_accuracy = cross_val_score(xgbc_model, X_res, y_res, cv=5, scoring='accuracy')\n",
    "crossV_f1 = cross_val_score(xgbc_model, X_res, y_res, cv=5, scoring='f1')\n",
    "crossV_predict = cross_val_predict(xgbc_model, X_res, y_res, cv=5, method='predict')\n",
    "print('accuracy: ', crossV_accuracy)\n",
    "print('f1 score: ', crossV_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = tree.DecisionTreeClassifier()\n",
    "dtc = dtc.fit(X_train, y_train)\n",
    "\n",
    "predictions = dtc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('accuracy: ',accuracy)\n",
    "print('f1 score: ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossV_accuracy = cross_val_score(xgbc_model, X_res, y_res, cv=5, scoring='accuracy')\n",
    "crossV_f1 = cross_val_score(xgbc_model, X_res, y_res, cv=5, scoring='f1')\n",
    "crossV_predict = cross_val_predict(xgbc_model, X_res, y_res, cv=5, method='predict')\n",
    "print('accuracy: ', crossV_accuracy)\n",
    "print('f1 score: ', crossV_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC(kernel='linear')\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "predictions = svm_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('accuracy: ',accuracy)\n",
    "print('f1 score: ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossV_accuracy = cross_val_score(svm_model, X_res, y_res, cv=5, scoring='accuracy')\n",
    "crossV_f1 = cross_val_score(svm_model, X_res, y_res, cv=5, scoring='f1')\n",
    "crossV_predict = cross_val_predict(svm_model, X_res, y_res, cv=5, method='predict')\n",
    "print('accuracy: ', crossV_accuracy)\n",
    "print('f1 score: ', crossV_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stck_model = StackingClassifier(\n",
    "    estimators=[('rf', rf_model), ('xgb', xgbc_model), ('log reg', clf), ('decision tree', dtc), ('svm', svm_model)],\n",
    "    final_estimator=xgbc_model\n",
    ")\n",
    "stck_model.fit(X_train, y_train)\n",
    "stck_predictions = stck_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, stck_predictions)\n",
    "r2_score = stck_model.score(X_test, stck_predictions)\n",
    "f1 = f1_score(y_test, stck_predictions)\n",
    "print('accuracy: ',accuracy)\n",
    "print('f1 score: ',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, stck_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossV_accuracy = cross_val_score(stck_model, X_res, y_res, cv=5, scoring='accuracy')\n",
    "crossV_f1 = cross_val_score(stck_model, X_res, y_res, cv=5, scoring='f1')\n",
    "crossV_predict = cross_val_predict(stck_model, X_res, y_res, cv=5, method='predict')\n",
    "print('accuracy: ', crossV_accuracy)\n",
    "print('f1 score: ', crossV_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_importance=clf.coef_[0]\n",
    "rf_importance = rf_model.feature_importances_\n",
    "xgbc_importance = xgbc_model.feature_importances_\n",
    "dtc_importance = dtc.feature_importances_\n",
    "svm_importance = svm_model.coef_[0]\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'log_reg': log_reg_importance,\n",
    "                                      'random_forest': rf_importance, 'XGBClassifier': xgbc_importance,\n",
    "                                      'decision_tree': dtc_importance, 'svm': svm_importance\n",
    "                                      })\n",
    "feature_importance_df['log_reg'] = (feature_importance_df['log_reg'].abs())/(feature_importance_df['log_reg'].abs().sum())\n",
    "feature_importance_df['svm'] = (feature_importance_df['svm'].abs())/(feature_importance_df['svm'].abs().sum())\n",
    "feature_importance_df['feature_avg'] = np.mean([feature_importance_df['log_reg'].values, rf_importance, xgbc_importance,\n",
    "                                                dtc_importance, feature_importance_df['svm'].values], axis=0)\n",
    "feature_importance_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
